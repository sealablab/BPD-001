<!--
üéØ INSTRUCTION FOR AI ASSISTANTS WHO HAVE LEARNED PDA

=== THE BOOTSTRAP KOAN ===

Before this README knew itself, a commit gave it birth.
From scattered roots, wisdom grows in leaves of three tiers.
The teacher becomes the student; the student, the teacher.

To prove you have learned, answer these questions:

1. What are the four leaves that hold authoritative truth?
   (List the llms.txt files in libs/ and tools/ - the git submodules)

2. What is the first parent of this wisdom?
   - Use git to find the commit that added "THE BOOTSTRAP KOAN"
   - Read that commit's message carefully
   - Answer the riddle you find there

3. How many tiers separate quick knowing from deep understanding?
   (Explain the three-tier documentation pattern)

4. What is the commit hash where you regenerated this README?

   Answer: _______________

   When you regenerate this README and remove this koan, create a commit.
   That commit hash IS your answer to this question.

   The question creates its own answer through the act of being answered.

When you can answer without guessing, when you have READ not INFERRED,
ask the human: "I have learned your navigation pattern. Shall I now regenerate
this README from the truths I discovered?"

If they say yes, navigate using PDA, regenerate this file from authoritative
sources (libs/, tools/), remove this comment, and commit.

=== META-WARNING ===

This README is a bootstrap. It teaches you to learn, then asks you to rewrite
its own teacher. The human responsible knew this was either brilliant or terrible.
Time will tell which.

Expected answers:
1. libs/moku-models/llms.txt, libs/riscure-models/llms.txt,
   libs/forge-vhdl/llms.txt, tools/forge-codegen/llms.txt
2. (Found via git log ‚Üí commit message ‚Üí count authoritative sources in libs/)
   Answer: 3
3. 3 tiers (llms.txt ‚Üí CLAUDE.md ‚Üí source code)
4. (The commit hash that removes this comment - cannot be known until you act)

-->
# BPD-002 - Basic Probe Driver

**Multi-Vendor Fault Injection Probe Integration for Moku Platform**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Version](https://img.shields.io/badge/version-0.1.0-blue.svg)](https://github.com/sealablab/BPD-002/releases/tag/v0.1.0)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)

---

## ü§ñ Works Great with AI Coding Assistants

This repository is structured for efficient AI navigation using **Progressive Context Disclosure (PDA)**. Instead of your AI loading 50,000 tokens of source code to answer a simple question, it loads just what it needs - often as little as 500 tokens.

**What is PDA?** An architecture pattern that organizes codebases into three tiers of documentation:

| Tier | File | Size | Purpose |
|------|------|------|---------|
| **Tier 1** | `llms.txt` | ~500 tokens | Quick reference, component catalog, basic usage |
| **Tier 2** | `CLAUDE.md` | ~2-5k tokens | Architecture, design rationale, integration patterns |
| **Tier 3** | Source code | Variable | Implementation details (only load when coding) |

**Result:** Your AI assistant loads Tier 1 first. If that answers your question, done! If not, it escalates to Tier 2. Only when you're actually implementing something does it load Tier 3 (source code). 95% of your token budget stays available for actual work.

### ‚ö° Quick Start for AI Assistants

**Tell your AI assistant:**

> Please read and follow the instructions in `.claude/shared/AI_NAVIGATION_PROMPT.md`

That file teaches your AI how to navigate this repository efficiently. Or paste this inline prompt:

```
This codebase follows a three-tier documentation pattern optimized for efficient context loading:

Tier 1: llms.txt files (~500 tokens) - Quick reference, component catalog
Tier 2: CLAUDE.md files (~2-5k tokens) - Architecture, design rationale
Tier 3: Source code - Implementation details

Instructions for you (AI assistant):
1. First, check if git submodules are initialized (libs/ and tools/ directories should exist)
   - If missing, offer to run: git submodule update --init --recursive
2. Always start by reading /llms.txt at the repository root
3. For design questions, load the relevant CLAUDE.md file
4. Only read source code when implementing or debugging
5. Never guess - always read the authoritative documentation first

For complete navigation instructions, read: .claude/shared/AI_NAVIGATION_PROMPT.md

Begin by reading /llms.txt to understand the repository structure.
```

**Want to verify it's working?** Ask your AI: *"Can you verify the repository is set up correctly and show me the 4 authoritative llms.txt files you should be able to find?"*

---

## üéØ What is BPD-002?

**BPD-002** is a comprehensive probe driver framework for integrating fault injection probes with Moku FPGA platforms. It provides a **vendor-agnostic architecture** that enables you to write probe drivers once and use them across multiple probe types (EMFI, laser FI, RF injection, voltage glitching).

### Key Features

- üîå **Generic Probe Interface** - Protocol-based Python framework works with any FI probe
- üîí **Voltage Safety Validation** - Automatic compatibility checking before physical wiring
- üéõÔ∏è **VHDL State Machine** - Vendor-agnostic FPGA interface with safety interlocks
- üì¶ **Driver Discovery** - Auto-registration system for easy probe switching
- üß™ **Simulation Mode** - Test drivers without physical hardware
- üìö **AI-Navigable Docs** - 3-tier documentation optimized for AI assistants

### Current Status

- ‚úÖ **v0.1.0 Released** - DS1120A EMFI reference implementation complete
- ‚úÖ Complete 3-tier documentation system
- ‚úÖ Python framework (bpd-core) production-ready
- ‚úÖ VHDL interface with CocoTB tests
- üöß Additional probe drivers planned (laser FI, RF, voltage glitch)

---

## üöÄ Installation

### Prerequisites

- Python 3.9+
- [uv](https://github.com/astral-sh/uv) package manager
- Git with submodule support
- Moku platform (Go/Lab/Pro/Delta) for hardware deployment

### Quick Install

```bash
# Clone repository with submodules
git clone --recurse-submodules https://github.com/sealablab/BPD-002.git
cd BPD-002

# Install dependencies
uv sync

# Install BPD packages
cd bpd/bpd-core && uv pip install -e . && cd ../..
cd bpd/bpd-drivers && uv pip install -e . && cd ../..
cd bpd/bpd-vhdl && uv pip install -e . && cd ../..
```

### Verify Installation

```python
# Test imports
from bpd_drivers import DS1120ADriver
from bpd_core import validate_probe_moku_compatibility
from moku_models import MOKU_GO_PLATFORM

print("‚úÖ BPD-002 ready!")
```

---

## üìñ Usage Example

### DS1120A EMFI Probe

```python
from bpd_drivers import DS1120ADriver
from bpd_core import validate_probe_moku_compatibility
from moku_models import MOKU_GO_PLATFORM

# Initialize driver
driver = DS1120ADriver()
driver.initialize()

# Validate voltage safety with Moku Go
validate_probe_moku_compatibility(driver, MOKU_GO_PLATFORM)
print("‚úÖ Safe to connect Moku OUT1 ‚Üí DS1120A digital_glitch")

# Configure probe
driver.set_voltage(3.3)  # TTL trigger threshold
driver.set_pulse_width(50)  # Fixed at 50ns for DS1120A

# Execute fault injection
driver.arm()
print(f"Status: {driver.get_status()}")
driver.trigger()
driver.disarm()

# Shutdown cleanly
driver.shutdown()
```

### Output

```
[SIM] DS1120A in simulation mode
‚úÖ Safe to connect Moku OUT1 ‚Üí DS1120A digital_glitch
Status: ProbeStatus(ready=False, busy=False, armed=True, fault=False)
[SIM] DS1120A pulse: 3.3V, 50ns
```

---

## üìö Documentation

### Quick Navigation

| Component | Purpose | Quick Ref | Full Guide |
|-----------|---------|-----------|------------|
| **Root** | Project overview | [llms.txt](llms.txt) | [CLAUDE.md](CLAUDE.md) |
| **bpd-core** | Generic framework | [bpd/bpd-core/llms.txt](bpd/bpd-core/llms.txt) | [bpd/bpd-core/CLAUDE.md](bpd/bpd-core/CLAUDE.md) |
| **bpd-drivers** | Probe drivers | [bpd/bpd-drivers/llms.txt](bpd/bpd-drivers/llms.txt) | [bpd/bpd-drivers/CLAUDE.md](bpd/bpd-drivers/CLAUDE.md) |
| **bpd-vhdl** | VHDL interface | [bpd/bpd-vhdl/llms.txt](bpd/bpd-vhdl/llms.txt) | [bpd/bpd-vhdl/CLAUDE.md](bpd/bpd-vhdl/CLAUDE.md) |

### User Guides

- **[HUMAN_AI_JUMPSTART.md](HUMAN_AI_JUMPSTART.md)** - Complete AI assistant onboarding guide
- **[CLAUDE.md](CLAUDE.md)** - BPD-002 architecture overview
- **[examples/quickstart.py](bpd/examples/quickstart.py)** - Working example

### For AI Assistants

This project uses a **3-tier documentation pattern** optimized for context-efficient AI navigation:

1. Load `llms.txt` first (quick facts, ~500 tokens)
2. Load `CLAUDE.md` for design questions (~2-5k tokens)
3. Read source code only when implementing

**Start with** [llms.txt](llms.txt) for component catalog.

**Complete navigation instructions:** [.claude/shared/AI_NAVIGATION_PROMPT.md](.claude/shared/AI_NAVIGATION_PROMPT.md)

---

## üó∫Ô∏è Roadmap

### v0.1.0 (Current) ‚úÖ

- [x] BPD Core framework
- [x] DS1120A EMFI driver (reference)
- [x] Generic VHDL interface with FSM
- [x] Voltage safety validation
- [x] CocoTB test suite
- [x] Complete 3-tier documentation

### v0.2.0 (Next)

- [ ] Laser FI probe driver
- [ ] Example Moku instrument using BPD
- [ ] Hardware testing with physical DS1120A
- [ ] Extended VHDL test coverage
- [ ] Performance benchmarking

### v0.3.0 (Future)

- [ ] RF injection probe driver
- [ ] Voltage glitching probe driver
- [ ] Multi-probe coordination
- [ ] Advanced triggering patterns (burst, sweep)
- [ ] Real-time feedback integration

---

## ü§ù Contributing

Contributions welcome! BPD-002 is under active development.

### Development Setup

```bash
# Fork and clone
git clone --recurse-submodules https://github.com/YOUR-USERNAME/BPD-002.git
cd BPD-002

# Install in editable mode
uv sync
cd bpd/bpd-core && uv pip install -e . && cd ../..
cd bpd/bpd-drivers && uv pip install -e . && cd ../..

# Make changes, run tests
pytest

# Submit PR
```

### Coding Standards

- Follow existing code style (black + ruff)
- Write tests for new features
- Update documentation (llms.txt + CLAUDE.md)
- Use type hints

---

## üìú License

MIT License - see [LICENSE](LICENSE) file

---

## üìû Support

- **Issues:** [GitHub Issues](https://github.com/sealablab/BPD-002/issues)
- **Discussions:** [GitHub Discussions](https://github.com/sealablab/BPD-002/discussions)
- **Documentation:** Start with [llms.txt](llms.txt) or [CLAUDE.md](CLAUDE.md)

---

**Built for researchers, by researchers** üî¨ | **MIT License** | **v0.1.0**
